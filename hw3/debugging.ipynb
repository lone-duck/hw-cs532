{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6439bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation based likelihood weighting\n",
    "\n",
    "from daphne import daphne\n",
    "from primitives import eval_env\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "ENV = None\n",
    "\n",
    "def likelihood_weighting_with_report(ast, L):\n",
    "    result = likelihood_weighting(ast, L)\n",
    "    returns = torch.stack(result['returns'])\n",
    "    log_weights = torch.stack(result['log_weights'])\n",
    "    unnormalized_weights = torch.exp(log_weights)\n",
    "    normalized_weights = unnormalized_weights/torch.sum(unnormalized_weights)\n",
    "    \n",
    "    if returns.dim() > 1:\n",
    "        weighted_returns = normalized_weights.unsqueeze(dim=1)*returns\n",
    "        expectations = torch.sum(weighted_returns, dim=0)\n",
    "    else:\n",
    "        weighted_returns = normalized_weights*returns\n",
    "        expectations = torch.sum(weighted_returns)\n",
    "    \n",
    "    \n",
    "    print(expectations)\n",
    "\n",
    "def likelihood_weighting_and_save(ast, L, filename):\n",
    "    result = likelihood_weighting(ast, L)\n",
    "    f = open(filename, 'wb')\n",
    "    pickle.dump(result, f)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def likelihood_weighting(ast, L):\n",
    "    \"\"\"\n",
    "    Generate likelihood weighted samples from a program desugared by Daphne.\n",
    "    Args:\n",
    "        ast: json FOPPL program\n",
    "        L: number of samples to generate\n",
    "    Return:\n",
    "        L samples and likelihood weights in a dictionary\n",
    "    \"\"\"\n",
    "    returns = [None]*L\n",
    "    log_weights = [None]*L\n",
    "\n",
    "    for l in range(L):\n",
    "        returns[l], log_weights[l] = evaluate_program(ast)\n",
    "\n",
    "    return {'returns': returns, 'log_weights': log_weights}\n",
    "\n",
    "\n",
    "def evaluate_program(ast):\n",
    "    \"\"\"Evaluate a program as desugared by daphne, generate a sample from the prior\n",
    "    Args:\n",
    "        ast: json FOPPL program\n",
    "    Returns: \n",
    "        samples with likelihood weights\n",
    "    \"\"\"\n",
    "    global ENV\n",
    "    ENV = eval_env()\n",
    "    for defn in ast[:-1]:\n",
    "        f_name = defn[1]\n",
    "        f_v_is = defn[2]\n",
    "        f_expr = defn[3]\n",
    "        ENV.update({f_name: (f_v_is, f_expr)})\n",
    "    l = {}\n",
    "    sig = {'logW': 0}\n",
    "    ret, sig = evaluate(ast[-1], l, sig)\n",
    "    return ret, sig['logW']\n",
    "\n",
    "# inspired by https://norvig.com/lispy.html\n",
    "def evaluate(e, l, sig):\n",
    "    # variable reference OR procedure OR just a string\n",
    "    if isinstance(e, str):        \n",
    "        # global procedures take precedence over locally defined vars\n",
    "        if e in ENV:\n",
    "            return ENV[e], sig\n",
    "        elif e in l:\n",
    "            return l[e], sig\n",
    "        # could allow for hashmaps with string keys; for debugging setting this to fail\n",
    "        else:\n",
    "            assert False, \"Unknown symbol: {}\".format(e)\n",
    "    # constant number\n",
    "    elif isinstance(e, (int, float)):   \n",
    "        return torch.tensor(float(e)), sig\n",
    "    # if statements\n",
    "    elif e[0] == 'if':\n",
    "        (_, test, conseq, alt) = e\n",
    "        test_value, sig = evaluate(test, l, sig)\n",
    "        expr = (conseq if test_value else alt)\n",
    "        return evaluate(expr, l, sig)\n",
    "    # let statements\n",
    "    elif e[0] == 'let':\n",
    "        # get symbol\n",
    "        symbol = e[1][0]\n",
    "        # get value of e1\n",
    "        value, sig = evaluate(e[1][1], l, sig)\n",
    "        # evaluate e2 with value \n",
    "        return evaluate(e[2], {**l, symbol: value}, sig)\n",
    "    # sample statement\n",
    "    if e[0] == 'sample':\n",
    "        dist, sig = evaluate(e[1], l, sig)\n",
    "        # make sure it is a distribution object\n",
    "        assert getattr(dist, '__module__', None).split('.')[:2] == ['torch', 'distributions']\n",
    "        return dist.sample(), sig\n",
    "    # observe statements\n",
    "    if e[0] == 'observe':\n",
    "        dist, sig = evaluate(e[1], l, sig) # get dist\n",
    "        y, sig = evaluate(e[2], l, sig)    # get observed value\n",
    "        # make sure it is a distribution object\n",
    "        assert getattr(dist, '__module__', None).split('.')[:2] == ['torch', 'distributions']\n",
    "        sig['logW'] = sig['logW'] + dist.log_prob(y)\n",
    "        return y, sig\n",
    "    # procedure call, either primitive or user-defined\n",
    "    else:            \n",
    "        proc, sig = evaluate(e[0], l, sig)\n",
    "        # primitives are functions\n",
    "        if callable(proc):\n",
    "            args = [None]*len(e[1:])\n",
    "            for i, arg in enumerate(e[1:]):\n",
    "                result, sig = evaluate(arg, l, sig)\n",
    "                args[i] = result\n",
    "            result = proc(*args)\n",
    "            return result, sig\n",
    "        # user defined functions are not\n",
    "        else:\n",
    "            # as written in algorithm 6\n",
    "            v_is, e0 = proc \n",
    "            assert(len(v_is) == len(e[1:]))\n",
    "            c_is = [None]*len(e[1:])\n",
    "            for i, arg in enumerate(e[1:]):\n",
    "                result, sig = evaluate(arg, l, sig)\n",
    "                c_is[i] = result\n",
    "            l_proc = dict(zip(v_is, c_is))\n",
    "            return evaluate(e0, {**l, **l_proc}, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd8955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('asts/3.json', 'rb')\n",
    "ast3 = json.load(f)\n",
    "f.close()\n",
    "#print(ast3)\n",
    "#print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2411257",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = likelihood_weighting(ast3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047017e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-41.2165)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['log_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87a312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = likelihood_weighting(ast3, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd3d47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = torch.stack(result['returns']).float()\n",
    "log_weights = torch.stack(result['log_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a3a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1.,  ..., 0., 1., 1.])\n",
      "tensor([-1040.0190,  -273.2407, -1250.9554,  ..., -1312.2267,  -360.9262,\n",
      "         -266.6620])\n"
     ]
    }
   ],
   "source": [
    "print(returns)\n",
    "print(log_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ac3bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.max(log_weights)\n",
    "m = torch.min(log_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684ab464",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_weights = torch.exp(log_weights)/torch.sum(torch.exp(log_weights))\n",
    "M_weights = torch.exp(log_weights-M)/torch.sum(torch.exp(log_weights-M))\n",
    "m_weights = torch.exp(log_weights-m)/torch.sum(torch.exp(log_weights-m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7ea7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15131, 1])\n",
      "torch.Size([15250, 1])\n",
      "torch.Size([99999, 1])\n"
     ]
    }
   ],
   "source": [
    "print(torch.nonzero(og_weights).size())\n",
    "print(torch.nonzero(M_weights).size())\n",
    "print(torch.nonzero(m_weights).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a078bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan, nan, nan,  ..., nan, nan, nan])\n"
     ]
    }
   ],
   "source": [
    "print(m_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d468d336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0829)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(og_weights*returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b1df39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0829)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(M_weights*returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52e645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34754d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352c1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4bcc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
