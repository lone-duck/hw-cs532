{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37afd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from primitives import eval_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71c237c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('graphs/1.json', 'rb')\n",
    "g1 = json.load(f)\n",
    "f.close()\n",
    "f = open('graphs/2.json', 'rb')\n",
    "g2 = json.load(f)\n",
    "f.close()\n",
    "f = open('graphs/3.json', 'rb')\n",
    "g3 = json.load(f)\n",
    "f.close()\n",
    "f = open('graphs/4.json', 'rb')\n",
    "g4 = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69e39cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = eval_env()\n",
    "\n",
    "# utilities for graph based sampling\n",
    "\n",
    "def deterministic_evaluate(e, l, sig=None):\n",
    "    # variable reference OR procedure OR just a string\n",
    "    if isinstance(e, str):        \n",
    "        # global procedures take precedence over locally defined vars\n",
    "        if e in ENV:\n",
    "            return ENV[e], sig\n",
    "        elif e in l:\n",
    "            return l[e], sig\n",
    "        # could allow for hashmaps with string keys; for debugging setting this to fail\n",
    "        else:\n",
    "            assert False, \"Unknown symbol: {}\".format(e)\n",
    "    # constant number\n",
    "    elif isinstance(e, (int, float)):   \n",
    "        return torch.tensor(float(e)), sig\n",
    "    # if statements\n",
    "    elif e[0] == 'if':\n",
    "        (_, test, conseq, alt) = e\n",
    "        exp = (conseq if deterministic_evaluate(test, l)[0] else alt)\n",
    "        return deterministic_evaluate(exp, l)\n",
    "    # let statements\n",
    "    elif e[0] == 'let':\n",
    "        # get symbol\n",
    "        symbol = e[1][0]\n",
    "        # get value of e1\n",
    "        value, _ = deterministic_evaluate(e[1][1], l)\n",
    "        # evaluate e2 with value \n",
    "        return deterministic_evaluate(e[2], {**l, symbol: value})\n",
    "    # sample statement\n",
    "    if e[0] == 'sample':\n",
    "        dist = deterministic_evaluate(e[1], l)[0]\n",
    "        # make sure it is a distribution object\n",
    "        assert getattr(dist, '__module__', None).split('.')[:2] == ['torch', 'distributions']\n",
    "        return dist.sample(), sig\n",
    "    # obsere statements\n",
    "    # TODO: change this, maybe in this hw or for hw3\n",
    "    if e[0] == 'observe':\n",
    "        dist = deterministic_evaluate(e[1], l)[0] # get dist\n",
    "        y = deterministic_evaluate(e[2], l)[0]    # get observed value\n",
    "        # make sure it is a distribution object\n",
    "        assert getattr(dist, '__module__', None).split('.')[:2] == ['torch', 'distributions']\n",
    "        # TODO: do something with observed value\n",
    "        return dist.sample(), sig\n",
    "    # procedure call, either primitive or user-defined\n",
    "    else:\n",
    "        result = deterministic_evaluate(e[0], l)\n",
    "        proc, sig = result\n",
    "        # primitives are functions\n",
    "        if callable(proc):\n",
    "            args = [deterministic_evaluate(arg, l)[0] for arg in e[1:]]\n",
    "            result, sig = proc(*args), sig\n",
    "            return result, sig\n",
    "        # user defined functions are not\n",
    "        else:\n",
    "            # as written in algorithm 6\n",
    "            v_is, e0 = proc \n",
    "            assert(len(v_is) == len(e[1:]))\n",
    "            c_is = [deterministic_evaluate(arg, l)[0] for arg in e[1:]]\n",
    "            l_proc = dict(zip(v_is, c_is))\n",
    "            return deterministic_evaluate(e0, {**l, **l_proc})\n",
    "\n",
    "# inspired by https://www.geeksforgeeks.org/python-program-for-topological-sorting/\n",
    "# TODO: update to python 3.9 and use graphlib instead\n",
    "def topological_sort(A, V):\n",
    "    visited = {v:False for v in V}\n",
    "    stack = []\n",
    "    \n",
    "    for v in V:\n",
    "        if visited[v] == False:\n",
    "            topo_sort_util(v, A, V, visited, stack)\n",
    "            \n",
    "    return stack\n",
    "\n",
    "def topo_sort_util(v, A, V, visited, stack):\n",
    "    \n",
    "    visited[v] = True\n",
    "    \n",
    "    if v in A:\n",
    "        for adj_v in A[v]:\n",
    "            if visited[adj_v] == False:\n",
    "                topo_sort_util(adj_v, A, V, visited, stack)\n",
    "            \n",
    "    stack.insert(0, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d5991",
   "metadata": {},
   "source": [
    "# Graph 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82950dbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = g3\n",
    "print(g3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33b4c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_prior(graph):\n",
    "    # get contents of graph\n",
    "    fn_defs = graph[0]\n",
    "    V = graph[1]['V']\n",
    "    A = graph[1]['A']\n",
    "    P = graph[1]['P']\n",
    "    Y = graph[1]['Y']\n",
    "    ret_vals = graph[2]\n",
    "    \n",
    "    # deal with fn_defs\n",
    "    global ENV\n",
    "    ENV = eval_env()\n",
    "    for defn in fn_defs.items():\n",
    "        f_name = defn[0]\n",
    "        f_v_is = defn[1][1]\n",
    "        f_expr = defn[1][2]\n",
    "        ENV.update({f_name: (f_v_is, f_expr)})\n",
    "    \n",
    "    # get sorted V\n",
    "    sorted_V = topological_sort(A, V)\n",
    "\n",
    "    # compute each value in order\n",
    "    l = {}\n",
    "    for v in sorted_V:\n",
    "        task, expr = P[v][0], P[v][1]\n",
    "        if task == \"sample*\":\n",
    "            dist, _ = deterministic_evaluate(expr, l)\n",
    "            l.update({v: dist.sample()})\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06c3cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = sample_from_prior(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0690192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample3': tensor(0.0404), 'sample1': tensor(2.1421), 'sample2': tensor(-6.0278), 'sample4': tensor(-5.6020), 'sample6': tensor([0.0235, 0.9545, 0.0221]), 'sample11': tensor(1), 'sample13': tensor(1), 'sample19': tensor(1), 'sample15': tensor(1), 'sample9': tensor(1), 'sample7': tensor(1), 'sample17': tensor(1), 'sample0': tensor(-0.7293), 'sample5': tensor(0.3977)}\n"
     ]
    }
   ],
   "source": [
    "print(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aebb0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gibbs step\n",
    "X = X0\n",
    "P = graph[1]['P']\n",
    "unif = torch.distributions.Uniform(0,1)\n",
    "Xkeys = list(X.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1551b430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample11\n",
      "Categorical(probs: torch.Size([3]))\n",
      "{'sample3': tensor(0.1025), 'sample1': tensor(1.0373), 'sample2': tensor(-0.5321), 'sample4': tensor(-1.5413), 'sample6': tensor([0.5471, 0.3383, 0.1146]), 'sample11': tensor(0), 'sample13': tensor(0), 'sample19': tensor(0), 'sample15': tensor(0), 'sample9': tensor(0), 'sample7': tensor(2), 'sample17': tensor(2), 'sample0': tensor(-11.5455), 'sample5': tensor(2.3074)}\n",
      "{'sample3': tensor(0.1025), 'sample1': tensor(1.0373), 'sample2': tensor(-0.5321), 'sample4': tensor(-1.5413), 'sample6': tensor([0.5471, 0.3383, 0.1146]), 'sample11': tensor(1), 'sample13': tensor(0), 'sample19': tensor(0), 'sample15': tensor(0), 'sample9': tensor(0), 'sample7': tensor(2), 'sample17': tensor(2), 'sample0': tensor(-11.5455), 'sample5': tensor(2.3074)}\n"
     ]
    }
   ],
   "source": [
    "x = Xkeys[5]\n",
    "task, expr = P[x][0], P[x][1]\n",
    "assert task == \"sample*\", \"Found observed variable in X???\"\n",
    "q, _ = deterministic_evaluate(expr, X)\n",
    "Xprime = X.copy()\n",
    "Xprime[x] = q.sample()\n",
    "print(x)\n",
    "print(q)\n",
    "print(X)\n",
    "print(Xprime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84a2db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample11\n",
      "sample3\n",
      "tensor(True)\n",
      "sample1\n",
      "tensor(True)\n",
      "sample2\n",
      "tensor(True)\n",
      "sample4\n",
      "tensor(True)\n",
      "sample6\n",
      "tensor([True, True, True])\n",
      "sample11\n",
      "tensor(False)\n",
      "sample13\n",
      "tensor(True)\n",
      "sample19\n",
      "tensor(True)\n",
      "sample15\n",
      "tensor(True)\n",
      "sample9\n",
      "tensor(True)\n",
      "sample7\n",
      "tensor(True)\n",
      "sample17\n",
      "tensor(True)\n",
      "sample0\n",
      "tensor(True)\n",
      "sample5\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "for k in X.keys():\n",
    "    print(k)\n",
    "    print(X[k] == Xprime[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f07ff521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.6031)\n",
      "tensor(-1.0838)\n"
     ]
    }
   ],
   "source": [
    "P = graph[1]['P']\n",
    "log_alpha = 0.0\n",
    "task, expr = P[x][0], P[x][1]\n",
    "assert task == \"sample*\", \"Found observed variable in X???\"\n",
    "q, _ = deterministic_evaluate(expr, X)\n",
    "qprime, _ = deterministic_evaluate(expr, Xprime)\n",
    "print(qprime.log_prob(X[x]))\n",
    "print(q.log_prob(Xprime[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fbe25589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['observe18', 'observe12', 'observe14', 'observe10', 'observe8', 'observe16', 'observe20', 'sample3']\n",
      "True\n",
      "['observe18', 'observe12', 'observe14', 'observe10', 'observe8', 'observe16', 'observe20', 'sample1']\n",
      "True\n",
      "['observe18', 'observe12', 'observe14', 'observe10', 'observe8', 'observe16', 'observe20', 'sample2']\n",
      "True\n",
      "['observe18', 'observe12', 'observe14', 'observe10', 'observe8', 'observe16', 'observe20', 'sample4']\n",
      "True\n",
      "['sample17', 'sample7', 'sample9', 'sample15', 'sample19', 'sample13', 'sample11', 'sample6']\n",
      "True\n",
      "['observe12', 'sample11']\n",
      "True\n",
      "['observe14', 'sample13']\n",
      "True\n",
      "['observe20', 'sample19']\n",
      "True\n",
      "['observe16', 'sample15']\n",
      "True\n",
      "['observe10', 'sample9']\n",
      "True\n",
      "['observe8', 'sample7']\n",
      "True\n",
      "['observe18', 'sample17']\n",
      "True\n",
      "['observe18', 'observe12', 'observe14', 'observe10', 'observe8', 'observe16', 'observe20', 'sample0']\n",
      "True\n",
      "['observe18', 'observe12', 'observe14', 'observe10', 'observe8', 'observe16', 'observe20', 'sample5']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for x in X.keys():\n",
    "    V_x = A[x] + [x]\n",
    "    XUY = {**X, **Y}\n",
    "    XprimeUY = {**Xprime, **Y}\n",
    "    for v in V_x:\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cfe592b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = {k: torch.tensor(v).float() for k,v in Y.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e702a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e94c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be3e23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5750533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c470db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d11125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3004cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c806d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
